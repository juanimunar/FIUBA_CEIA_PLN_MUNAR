{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj7N7G963SQE"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"250\" align=\"center\">\n",
        "\n",
        "**PROCESAMIENTO DE LENGUAJE NATURAL**\n",
        "\n",
        "*DESAFÍO Nº1 - BOTS - JUAN I. MUNAR*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYhOBELV31Rq"
      },
      "source": [
        "**1. BOT DNN + Spacy (PyTorch)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jneM9aUi4uUT"
      },
      "source": [
        "1.1. Instalo e importo dependencias, obtengo un diccionario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsmEXlYg40bQ"
      },
      "outputs": [],
      "source": [
        "# Librerías varias\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Ploteo\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Obtención resultados\n",
        "import torchsummary\n",
        "\n",
        "# Torch helpers\n",
        "import os\n",
        "import platform\n",
        "if os.access('torch_helpers.py', os.F_OK) is False:\n",
        "    if platform.system() == 'Windows':\n",
        "        !curl !wget https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py > torch_helpers.py\n",
        "    else:\n",
        "        !wget torch_helpers.py https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/scripts/torch_helpers.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "a7f714856e9d4c6b90be1be948d772d5",
            "eb8a3e16b70a419c81a1ef1cd0d5d57c",
            "ddc708f11390444b9bfda6606f4d667f",
            "7f30792aa5704c498a1818953ec74fc5",
            "0d5e569e1917434d832cfe034cdfd1ae",
            "a2b575d968864a80a248d4748ea1b215",
            "0cdbad0546734c4b98825419f1a947dd",
            "4a478e6d050443daab42df2a2016a853",
            "4432832534f349aa97296b817b244b53",
            "5184a539290d4a1bb2866d552f02a1b7",
            "cd73735126bb4696ab118c6931da84be"
          ]
        },
        "id": "g3wKMeYL6VpY",
        "outputId": "8036630f-d8db-4355-f59e-f4b57c5c87f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7f714856e9d4c6b90be1be948d772d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Downloading default packages for language: es (Spanish)...\n",
            "INFO:stanza:File exists: /root/stanza_resources/es/default.zip.\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "INFO:stanza:Loading these models for language: es (Spanish):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ancora  |\n",
            "| mwt       | ancora  |\n",
            "| pos       | ancora  |\n",
            "| lemma     | ancora  |\n",
            "| depparse  | ancora  |\n",
            "| ner       | conll02 |\n",
            "=======================\n",
            "\n",
            "INFO:stanza:Use device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "# La última versión de spacy-stanza (>1.0) es compatible solo con spacy >=3.0\n",
        "# Nota: spacy 3.0 incorpora al pepiline nlp transformers\n",
        "!pip install -U spacy==3.1 --quiet\n",
        "!pip install -U spacy-stanza==1.0.0 --quiet\n",
        "\n",
        "# SpaCy armó un wrapper para los pipelines y modelos de Stanza (librería de NLP de Stanford)\n",
        "import stanza\n",
        "import spacy_stanza\n",
        "\n",
        "# Descargo el diccionario en español y armo el pipeline de NLP con spacy\n",
        "stanza.download(\"es\")\n",
        "nlp = spacy_stanza.load_pipeline(\"es\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfGKstAW_QRB"
      },
      "source": [
        "1.2. Preprocesamiento del texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3y6FGEO6TZC"
      },
      "outputs": [],
      "source": [
        "# Librerías\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "# Función de preprocesamiento\n",
        "def preprocess_clean_text(text):\n",
        "    # Pasar todo el texto a minúsculas\n",
        "    text = text.lower()\n",
        "    # Sacar tildes de las palabras\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    # Quitar caracteres especiales\n",
        "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]'\n",
        "    # Quitar números\n",
        "    text = re.sub(pattern, '', text)\n",
        "    # Quitar caracteres de puntuación\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svOSJt_zIAsc"
      },
      "source": [
        "1.3. Diccionario de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7T13J2KHdtU"
      },
      "outputs": [],
      "source": [
        "# Diccionario de entrada en formato json con posibles preguntas y respuestas\n",
        "dataset = {\"intents\": [\n",
        "             {\"tag\": \"bienvenida\",\n",
        "              \"patterns\": [\"Hola\", \"¿Cómo estás?\", \"¿Qué tal?\", \"¿Cómo va?\", \"¿Cómo andas?\", \"Buen día\"],\n",
        "              \"responses\": [\"Hola, buen día, se ha comunicado con un centro de denuncias de bajo presupuesto. \\n ¿Cuál es el delito que desea denunciar?\"],\n",
        "             },\n",
        "             {\"tag\": \"estupefacientes\",\n",
        "              \"patterns\": [\"Están vendiendo drogas\", \"venden cocaína\",\n",
        "                           \"venden fafafa\", \"venden marihuana\",\n",
        "                           \"venden extásis\", \"venden pastillas\", \"venden LSD\",\n",
        "                           \"hay dealers\", \"narcotráfico\"],\n",
        "              \"responses\": [\"Dígame la dirección\"]\n",
        "             },\n",
        "             {\"tag\": \"direccion\",\n",
        "              \"patterns\": [\"la dirección es calle\", \"la ubicación es calle\", \"el lugar queda en\"],\n",
        "              \"responses\": [\"Envío un efectivos al lugar. ¿Algo más en que lo pueda ayudar?\"]\n",
        "             },\n",
        "            {\"tag\": \"homicidio\",\n",
        "              \"patterns\": [\"hubo un asesinato\", \"hubo un homicidio\",\n",
        "                           \"mataron a una persona\", \"mataron a alguien\",\n",
        "                           \"le dispararon a alguien\", \"le dispararon a mi\"],\n",
        "              \"responses\": [\"Por favor póngase a resguardo, Dígame la dirección\"]\n",
        "             },\n",
        "            {\"tag\": \"robo\",\n",
        "              \"patterns\": [\"hubo un robo\", \"hubo un hurto\", \"hay un ladrón\",\n",
        "                           \"hay un chorro\", \"me robaron\", \"le robaron\"],\n",
        "              \"responses\": [\"Si pudo identificar al ladrón, por favor dirijase a la comisaria más cercana para realizar un identikit. \\n ¿Algo más en que lo pueda ayudar? \"]\n",
        "             },\n",
        "            {\"tag\": \"heridos\",\n",
        "              \"patterns\": [ \"hay un herido\", \"hay un hombre lastimado\",\n",
        "                           \"hay una persona grave\", \"hay un quemado\",\n",
        "                           \"fue apuñalada\", \"estoy herido\", \"estoy lastimado\"],\n",
        "              \"responses\": [\"Hay una ambulancia en camino. ¿Algo más en que lo pueda ayudar?\"]\n",
        "             },\n",
        "             {\"tag\": \"fuego\",\n",
        "              \"patterns\": [ \"hay fuego\", \"hay un incendio\", \"se está quemando\"],\n",
        "              \"responses\": [\"Muy interesante, lo anotaré en mi máquina de escribir invisible\"]\n",
        "             },\n",
        "             {\"tag\": \"despedida\",\n",
        "              \"patterns\": [\"Adios\", \"Chau\", \"Hasta luego\", \"Bye\", \"ok\", \"si\", \"no\"],\n",
        "              \"responses\": [\"Gracias, adios\"]\n",
        "             }\n",
        "]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRKL1_AgOVpC"
      },
      "source": [
        "1.4. Preprocesamiento y armado del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0Mz2p6eHuPU",
        "outputId": "6443298f-5a59-40d5-bd58-7184de0b9937"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-de38f27299c1>:15: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  tokens = nlp(preprocess_clean_text(pattern))\n",
            "<ipython-input-5-de38f27299c1>:15: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['se', 'e', 'esta', 'quemando']\n",
            "Entities: []\n",
            "  tokens = nlp(preprocess_clean_text(pattern))\n"
          ]
        }
      ],
      "source": [
        "# Datos que necesitaremos, las palabras o vocabilario\n",
        "words = []\n",
        "classes = []\n",
        "doc_X = []\n",
        "doc_y = []\n",
        "\n",
        "# Por cada intención (intents) debemos tomar los patrones que la caracterízan\n",
        "# a esa intención y transformarla a tokens para almacenar en doc_X\n",
        "\n",
        "# El tag de cada intención se almacena como doc_Y (la clase a predecir)\n",
        "\n",
        "for intent in dataset[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        # trasformar el patron a tokens\n",
        "        tokens = nlp(preprocess_clean_text(pattern))\n",
        "        # lematizar los tokens\n",
        "        for token in tokens:\n",
        "            words.append(token.lemma_)\n",
        "\n",
        "        doc_X.append(pattern)\n",
        "        doc_y.append(intent[\"tag\"])\n",
        "\n",
        "    # Agregar el tag a las clases\n",
        "    if intent[\"tag\"] not in classes:\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "# Elminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsT8lwa-PMrq",
        "outputId": "fe9a5d0c-166b-4253-ef70-ece04972422b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "words: ['a', 'adios', 'alguien', 'andar', 'apunalar', 'asesinato', 'buen', 'bye', 'calle', 'chau', 'chorro', 'cocaina', 'como', 'dealers', 'dia', 'direccion', 'disparar', 'droga', 'e', 'el', 'en', 'estar', 'este', 'extasis', 'fafafa', 'fuego', 'grave', 'haber', 'hasta', 'herido', 'holar', 'hombre', 'homicidio', 'hurto', 'incendio', 'ir', 'ladron', 'lastimado', 'lsd', 'luego', 'lugar', 'marihuana', 'matar', 'mi', 'narcotrafico', 'no', 'ok', 'pastilla', 'persona', 'que', 'quedar', 'quemar', 'robar', 'robo', 'ser', 'si', 'tal', 'ubicacion', 'uno', 'vender', 'yo', 'él']\n",
            "classes: ['bienvenida', 'despedida', 'direccion', 'estupefacientes', 'fuego', 'heridos', 'homicidio', 'robo']\n",
            "doc_X: ['Hola', '¿Cómo estás?', '¿Qué tal?', '¿Cómo va?', '¿Cómo andas?', 'Buen día', 'Están vendiendo drogas', 'venden cocaína', 'venden fafafa', 'venden marihuana', 'venden extásis', 'venden pastillas', 'venden LSD', 'hay dealers', 'narcotráfico', 'la dirección es calle', 'la ubicación es calle', 'el lugar queda en', 'hubo un asesinato', 'hubo un homicidio', 'mataron a una persona', 'mataron a alguien', 'le dispararon a alguien', 'le dispararon a mi', 'hubo un robo', 'hubo un hurto', 'hay un ladrón', 'hay un chorro', 'me robaron', 'le robaron', 'hay un herido', 'hay un hombre lastimado', 'hay una persona grave', 'hay un quemado', 'fue apuñalada', 'estoy herido', 'estoy lastimado', 'hay fuego', 'hay un incendio', 'se está quemando', 'Adios', 'Chau', 'Hasta luego', 'Bye', 'ok', 'si', 'no']\n",
            "doc_y: ['bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'estupefacientes', 'estupefacientes', 'estupefacientes', 'estupefacientes', 'estupefacientes', 'estupefacientes', 'estupefacientes', 'estupefacientes', 'estupefacientes', 'direccion', 'direccion', 'direccion', 'homicidio', 'homicidio', 'homicidio', 'homicidio', 'homicidio', 'homicidio', 'robo', 'robo', 'robo', 'robo', 'robo', 'robo', 'heridos', 'heridos', 'heridos', 'heridos', 'heridos', 'heridos', 'heridos', 'fuego', 'fuego', 'fuego', 'despedida', 'despedida', 'despedida', 'despedida', 'despedida', 'despedida', 'despedida']\n"
          ]
        }
      ],
      "source": [
        "print(\"words:\", words)\n",
        "print(\"classes:\", classes)\n",
        "print(\"doc_X:\", doc_X)\n",
        "print(\"doc_y:\", doc_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oRiD0cTPwhw",
        "outputId": "5648be03-334b-4050-97b2-7e30529ba746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] y: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] y: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0] y: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1] y: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0] y: [0, 0, 0, 0, 1, 0, 0, 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-84adf1c05755>:10: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  tokens = nlp(preprocess_clean_text(doc))\n",
            "<ipython-input-7-84adf1c05755>:10: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['se', 'e', 'esta', 'quemando']\n",
            "Entities: []\n",
            "  tokens = nlp(preprocess_clean_text(doc))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] y: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "X: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "X: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] y: [0, 1, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "# Transformar doc_X en bag of words por oneHotEncoding\n",
        "# Transformar doc_Y en un vector de clases multicategórico con oneHotEncoding\n",
        "\n",
        "training = []\n",
        "out_empty = [0] * len(classes)\n",
        "\n",
        "for idx, doc in enumerate(doc_X):\n",
        "    # Transformar la pregunta (input) en tokens y lematizar\n",
        "    text = []\n",
        "    tokens = nlp(preprocess_clean_text(doc))\n",
        "    for token in tokens:\n",
        "        text.append(token.lemma_)\n",
        "\n",
        "    # Transformar los tokens en \"Bag of words\" (arrays de 1 y 0)\n",
        "    bow = []\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)\n",
        "\n",
        "    # Crear el array de salida (class output) correspondiente\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(doc_y[idx])] = 1\n",
        "\n",
        "    print(\"X:\", bow, \"y:\", output_row)\n",
        "    training.append([bow, output_row])\n",
        "\n",
        "# Mezclar los datos\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)\n",
        "# Dividir en datos de entrada y salida\n",
        "train_X = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhlH61cFP38l",
        "outputId": "f10788b5-3068-4586-acc3-e620e0141c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input dim 62\n",
            "Output dim 8\n"
          ]
        }
      ],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        # Convertir los arrays de numpy a tensores.\n",
        "        # pytorch espera en general entradas 32bits\n",
        "        self.x = torch.from_numpy(x.astype(np.float32))\n",
        "        # las loss function esperan la salida float\n",
        "        self.y = torch.from_numpy(y.astype(np.float32))\n",
        "\n",
        "        self.len = self.y.shape[0]\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "data_set = Data(train_X, train_y)\n",
        "\n",
        "input_dim = data_set.x.shape[1]\n",
        "print(\"Input dim\", input_dim)\n",
        "\n",
        "output_dim = data_set.y.shape[1]\n",
        "print(\"Output dim\", output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj9ZaBZmP-x8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(data_set, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWLPZ5FWQCXq",
        "outputId": "8674a7ff-ce5b-4ca8-d181-c767f47f3214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 128]           8,064\n",
            "              ReLU-2               [-1, 1, 128]               0\n",
            "           Dropout-3               [-1, 1, 128]               0\n",
            "            Linear-4                [-1, 1, 64]           8,256\n",
            "              ReLU-5                [-1, 1, 64]               0\n",
            "           Dropout-6                [-1, 1, 64]               0\n",
            "            Linear-7                 [-1, 1, 8]             520\n",
            "           Softmax-8                 [-1, 1, 8]               0\n",
            "================================================================\n",
            "Total params: 16,840\n",
            "Trainable params: 16,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.07\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features=input_dim, out_features=128) # fully connected layer\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64) # fully connected layer\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=output_dim) # fully connected layer\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1) # normalize in dim 1\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.fc1(x))\n",
        "        out = self.dropout(out)\n",
        "        out = self.relu(self.fc2(out))\n",
        "        out = self.dropout(out)\n",
        "        out = self.softmax(self.fc3(out))\n",
        "        return out\n",
        "\n",
        "# Crear el modelo basado en la arquitectura definida\n",
        "model1 = Model1(input_dim=input_dim, output_dim=output_dim)\n",
        "# Crear el optimizador la una función de error\n",
        "model1_optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "model1_criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
        "\n",
        "torchsummary.summary(model1, input_size=(1, input_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIXosxFYQHNx"
      },
      "outputs": [],
      "source": [
        "from torch_helpers import categorical_acc\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, epochs=100):\n",
        "    # Defino listas para realizar graficas de los resultados\n",
        "    train_loss = []\n",
        "    train_accuracy = []\n",
        "\n",
        "    ## Defino mi loop de entrenamiento\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_accuracy = 0.0\n",
        "\n",
        "        for train_data, train_target in train_loader:\n",
        "\n",
        "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
        "            # los va acumulando\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(train_data)\n",
        "\n",
        "            # Computo el error de la salida comparando contra las etiquetas\n",
        "            loss = criterion(output, train_target)\n",
        "\n",
        "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
        "            loss.backward()\n",
        "\n",
        "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculo el accuracy del batch\n",
        "            accuracy = categorical_acc(output, train_target)\n",
        "            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n",
        "            epoch_train_accuracy += accuracy.item()\n",
        "\n",
        "        # Calculo la media de error y accuracy para la epoca de entrenamiento.\n",
        "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
        "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
        "        train_accuracy.append(epoch_train_accuracy)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f}\")\n",
        "\n",
        "    history = {\n",
        "        \"loss\": train_loss,\n",
        "        \"accuracy\": train_accuracy,\n",
        "    }\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIs0qEiIQMdd",
        "outputId": "d740d942-09ba-4896-cfa7-9c24060678d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/300 - Train loss 2.082 - Train accuracy 0.047\n",
            "Epoch: 2/300 - Train loss 2.080 - Train accuracy 0.160\n",
            "Epoch: 3/300 - Train loss 2.077 - Train accuracy 0.192\n",
            "Epoch: 4/300 - Train loss 2.079 - Train accuracy 0.080\n",
            "Epoch: 5/300 - Train loss 2.077 - Train accuracy 0.160\n",
            "Epoch: 6/300 - Train loss 2.075 - Train accuracy 0.258\n",
            "Epoch: 7/300 - Train loss 2.075 - Train accuracy 0.327\n",
            "Epoch: 8/300 - Train loss 2.076 - Train accuracy 0.241\n",
            "Epoch: 9/300 - Train loss 2.075 - Train accuracy 0.263\n",
            "Epoch: 10/300 - Train loss 2.074 - Train accuracy 0.241\n",
            "Epoch: 11/300 - Train loss 2.071 - Train accuracy 0.325\n",
            "Epoch: 12/300 - Train loss 2.071 - Train accuracy 0.390\n",
            "Epoch: 13/300 - Train loss 2.069 - Train accuracy 0.309\n",
            "Epoch: 14/300 - Train loss 2.069 - Train accuracy 0.390\n",
            "Epoch: 15/300 - Train loss 2.066 - Train accuracy 0.327\n",
            "Epoch: 16/300 - Train loss 2.066 - Train accuracy 0.358\n",
            "Epoch: 17/300 - Train loss 2.062 - Train accuracy 0.421\n",
            "Epoch: 18/300 - Train loss 2.058 - Train accuracy 0.343\n",
            "Epoch: 19/300 - Train loss 2.061 - Train accuracy 0.441\n",
            "Epoch: 20/300 - Train loss 2.055 - Train accuracy 0.341\n",
            "Epoch: 21/300 - Train loss 2.053 - Train accuracy 0.405\n",
            "Epoch: 22/300 - Train loss 2.048 - Train accuracy 0.392\n",
            "Epoch: 23/300 - Train loss 2.042 - Train accuracy 0.405\n",
            "Epoch: 24/300 - Train loss 2.045 - Train accuracy 0.260\n",
            "Epoch: 25/300 - Train loss 2.042 - Train accuracy 0.358\n",
            "Epoch: 26/300 - Train loss 2.034 - Train accuracy 0.407\n",
            "Epoch: 27/300 - Train loss 2.030 - Train accuracy 0.360\n",
            "Epoch: 28/300 - Train loss 2.029 - Train accuracy 0.343\n",
            "Epoch: 29/300 - Train loss 2.005 - Train accuracy 0.341\n",
            "Epoch: 30/300 - Train loss 2.003 - Train accuracy 0.343\n",
            "Epoch: 31/300 - Train loss 2.000 - Train accuracy 0.325\n",
            "Epoch: 32/300 - Train loss 1.991 - Train accuracy 0.376\n",
            "Epoch: 33/300 - Train loss 1.985 - Train accuracy 0.276\n",
            "Epoch: 34/300 - Train loss 1.980 - Train accuracy 0.292\n",
            "Epoch: 35/300 - Train loss 1.986 - Train accuracy 0.260\n",
            "Epoch: 36/300 - Train loss 1.966 - Train accuracy 0.258\n",
            "Epoch: 37/300 - Train loss 1.934 - Train accuracy 0.358\n",
            "Epoch: 38/300 - Train loss 1.942 - Train accuracy 0.309\n",
            "Epoch: 39/300 - Train loss 1.915 - Train accuracy 0.358\n",
            "Epoch: 40/300 - Train loss 1.926 - Train accuracy 0.341\n",
            "Epoch: 41/300 - Train loss 1.901 - Train accuracy 0.423\n",
            "Epoch: 42/300 - Train loss 1.895 - Train accuracy 0.392\n",
            "Epoch: 43/300 - Train loss 1.884 - Train accuracy 0.374\n",
            "Epoch: 44/300 - Train loss 1.884 - Train accuracy 0.423\n",
            "Epoch: 45/300 - Train loss 1.868 - Train accuracy 0.407\n",
            "Epoch: 46/300 - Train loss 1.844 - Train accuracy 0.490\n",
            "Epoch: 47/300 - Train loss 1.838 - Train accuracy 0.490\n",
            "Epoch: 48/300 - Train loss 1.829 - Train accuracy 0.539\n",
            "Epoch: 49/300 - Train loss 1.810 - Train accuracy 0.539\n",
            "Epoch: 50/300 - Train loss 1.815 - Train accuracy 0.490\n",
            "Epoch: 51/300 - Train loss 1.811 - Train accuracy 0.521\n",
            "Epoch: 52/300 - Train loss 1.790 - Train accuracy 0.588\n",
            "Epoch: 53/300 - Train loss 1.811 - Train accuracy 0.552\n",
            "Epoch: 54/300 - Train loss 1.772 - Train accuracy 0.603\n",
            "Epoch: 55/300 - Train loss 1.745 - Train accuracy 0.590\n",
            "Epoch: 56/300 - Train loss 1.751 - Train accuracy 0.588\n",
            "Epoch: 57/300 - Train loss 1.747 - Train accuracy 0.554\n",
            "Epoch: 58/300 - Train loss 1.750 - Train accuracy 0.539\n",
            "Epoch: 59/300 - Train loss 1.737 - Train accuracy 0.634\n",
            "Epoch: 60/300 - Train loss 1.759 - Train accuracy 0.603\n",
            "Epoch: 61/300 - Train loss 1.717 - Train accuracy 0.617\n",
            "Epoch: 62/300 - Train loss 1.724 - Train accuracy 0.634\n",
            "Epoch: 63/300 - Train loss 1.706 - Train accuracy 0.681\n",
            "Epoch: 64/300 - Train loss 1.704 - Train accuracy 0.588\n",
            "Epoch: 65/300 - Train loss 1.700 - Train accuracy 0.652\n",
            "Epoch: 66/300 - Train loss 1.673 - Train accuracy 0.668\n",
            "Epoch: 67/300 - Train loss 1.681 - Train accuracy 0.683\n",
            "Epoch: 68/300 - Train loss 1.665 - Train accuracy 0.650\n",
            "Epoch: 69/300 - Train loss 1.639 - Train accuracy 0.701\n",
            "Epoch: 70/300 - Train loss 1.643 - Train accuracy 0.701\n",
            "Epoch: 71/300 - Train loss 1.616 - Train accuracy 0.732\n",
            "Epoch: 72/300 - Train loss 1.645 - Train accuracy 0.730\n",
            "Epoch: 73/300 - Train loss 1.618 - Train accuracy 0.699\n",
            "Epoch: 74/300 - Train loss 1.623 - Train accuracy 0.715\n",
            "Epoch: 75/300 - Train loss 1.616 - Train accuracy 0.732\n",
            "Epoch: 76/300 - Train loss 1.614 - Train accuracy 0.795\n",
            "Epoch: 77/300 - Train loss 1.564 - Train accuracy 0.746\n",
            "Epoch: 78/300 - Train loss 1.576 - Train accuracy 0.764\n",
            "Epoch: 79/300 - Train loss 1.579 - Train accuracy 0.764\n",
            "Epoch: 80/300 - Train loss 1.583 - Train accuracy 0.746\n",
            "Epoch: 81/300 - Train loss 1.587 - Train accuracy 0.699\n",
            "Epoch: 82/300 - Train loss 1.561 - Train accuracy 0.795\n",
            "Epoch: 83/300 - Train loss 1.593 - Train accuracy 0.730\n",
            "Epoch: 84/300 - Train loss 1.551 - Train accuracy 0.764\n",
            "Epoch: 85/300 - Train loss 1.524 - Train accuracy 0.748\n",
            "Epoch: 86/300 - Train loss 1.553 - Train accuracy 0.730\n",
            "Epoch: 87/300 - Train loss 1.543 - Train accuracy 0.795\n",
            "Epoch: 88/300 - Train loss 1.556 - Train accuracy 0.779\n",
            "Epoch: 89/300 - Train loss 1.559 - Train accuracy 0.764\n",
            "Epoch: 90/300 - Train loss 1.510 - Train accuracy 0.826\n",
            "Epoch: 91/300 - Train loss 1.499 - Train accuracy 0.795\n",
            "Epoch: 92/300 - Train loss 1.512 - Train accuracy 0.795\n",
            "Epoch: 93/300 - Train loss 1.536 - Train accuracy 0.748\n",
            "Epoch: 94/300 - Train loss 1.527 - Train accuracy 0.810\n",
            "Epoch: 95/300 - Train loss 1.526 - Train accuracy 0.761\n",
            "Epoch: 96/300 - Train loss 1.522 - Train accuracy 0.795\n",
            "Epoch: 97/300 - Train loss 1.517 - Train accuracy 0.795\n",
            "Epoch: 98/300 - Train loss 1.495 - Train accuracy 0.810\n",
            "Epoch: 99/300 - Train loss 1.495 - Train accuracy 0.826\n",
            "Epoch: 100/300 - Train loss 1.486 - Train accuracy 0.826\n",
            "Epoch: 101/300 - Train loss 1.497 - Train accuracy 0.810\n",
            "Epoch: 102/300 - Train loss 1.490 - Train accuracy 0.826\n",
            "Epoch: 103/300 - Train loss 1.497 - Train accuracy 0.826\n",
            "Epoch: 104/300 - Train loss 1.500 - Train accuracy 0.826\n",
            "Epoch: 105/300 - Train loss 1.475 - Train accuracy 0.810\n",
            "Epoch: 106/300 - Train loss 1.497 - Train accuracy 0.824\n",
            "Epoch: 107/300 - Train loss 1.480 - Train accuracy 0.808\n",
            "Epoch: 108/300 - Train loss 1.475 - Train accuracy 0.873\n",
            "Epoch: 109/300 - Train loss 1.460 - Train accuracy 0.889\n",
            "Epoch: 110/300 - Train loss 1.467 - Train accuracy 0.842\n",
            "Epoch: 111/300 - Train loss 1.447 - Train accuracy 0.873\n",
            "Epoch: 112/300 - Train loss 1.473 - Train accuracy 0.810\n",
            "Epoch: 113/300 - Train loss 1.470 - Train accuracy 0.857\n",
            "Epoch: 114/300 - Train loss 1.447 - Train accuracy 0.857\n",
            "Epoch: 115/300 - Train loss 1.455 - Train accuracy 0.904\n",
            "Epoch: 116/300 - Train loss 1.441 - Train accuracy 0.826\n",
            "Epoch: 117/300 - Train loss 1.433 - Train accuracy 0.889\n",
            "Epoch: 118/300 - Train loss 1.461 - Train accuracy 0.889\n",
            "Epoch: 119/300 - Train loss 1.449 - Train accuracy 0.842\n",
            "Epoch: 120/300 - Train loss 1.428 - Train accuracy 0.904\n",
            "Epoch: 121/300 - Train loss 1.440 - Train accuracy 0.920\n",
            "Epoch: 122/300 - Train loss 1.422 - Train accuracy 0.920\n",
            "Epoch: 123/300 - Train loss 1.437 - Train accuracy 0.920\n",
            "Epoch: 124/300 - Train loss 1.434 - Train accuracy 0.935\n",
            "Epoch: 125/300 - Train loss 1.436 - Train accuracy 0.920\n",
            "Epoch: 126/300 - Train loss 1.440 - Train accuracy 0.920\n",
            "Epoch: 127/300 - Train loss 1.419 - Train accuracy 0.920\n",
            "Epoch: 128/300 - Train loss 1.417 - Train accuracy 0.904\n",
            "Epoch: 129/300 - Train loss 1.410 - Train accuracy 0.935\n",
            "Epoch: 130/300 - Train loss 1.414 - Train accuracy 0.935\n",
            "Epoch: 131/300 - Train loss 1.431 - Train accuracy 0.920\n",
            "Epoch: 132/300 - Train loss 1.386 - Train accuracy 0.935\n",
            "Epoch: 133/300 - Train loss 1.414 - Train accuracy 0.904\n",
            "Epoch: 134/300 - Train loss 1.430 - Train accuracy 0.920\n",
            "Epoch: 135/300 - Train loss 1.390 - Train accuracy 0.920\n",
            "Epoch: 136/300 - Train loss 1.397 - Train accuracy 0.935\n",
            "Epoch: 137/300 - Train loss 1.390 - Train accuracy 0.920\n",
            "Epoch: 138/300 - Train loss 1.396 - Train accuracy 0.935\n",
            "Epoch: 139/300 - Train loss 1.403 - Train accuracy 0.935\n",
            "Epoch: 140/300 - Train loss 1.396 - Train accuracy 0.935\n",
            "Epoch: 141/300 - Train loss 1.380 - Train accuracy 0.935\n",
            "Epoch: 142/300 - Train loss 1.378 - Train accuracy 0.920\n",
            "Epoch: 143/300 - Train loss 1.410 - Train accuracy 0.920\n",
            "Epoch: 144/300 - Train loss 1.375 - Train accuracy 0.935\n",
            "Epoch: 145/300 - Train loss 1.382 - Train accuracy 0.920\n",
            "Epoch: 146/300 - Train loss 1.376 - Train accuracy 0.935\n",
            "Epoch: 147/300 - Train loss 1.380 - Train accuracy 0.935\n",
            "Epoch: 148/300 - Train loss 1.375 - Train accuracy 0.935\n",
            "Epoch: 149/300 - Train loss 1.403 - Train accuracy 0.935\n",
            "Epoch: 150/300 - Train loss 1.377 - Train accuracy 0.920\n",
            "Epoch: 151/300 - Train loss 1.359 - Train accuracy 0.935\n",
            "Epoch: 152/300 - Train loss 1.375 - Train accuracy 0.920\n",
            "Epoch: 153/300 - Train loss 1.378 - Train accuracy 0.920\n",
            "Epoch: 154/300 - Train loss 1.381 - Train accuracy 0.935\n",
            "Epoch: 155/300 - Train loss 1.361 - Train accuracy 0.935\n",
            "Epoch: 156/300 - Train loss 1.388 - Train accuracy 0.902\n",
            "Epoch: 157/300 - Train loss 1.370 - Train accuracy 0.935\n",
            "Epoch: 158/300 - Train loss 1.369 - Train accuracy 0.920\n",
            "Epoch: 159/300 - Train loss 1.377 - Train accuracy 0.920\n",
            "Epoch: 160/300 - Train loss 1.374 - Train accuracy 0.935\n",
            "Epoch: 161/300 - Train loss 1.372 - Train accuracy 0.935\n",
            "Epoch: 162/300 - Train loss 1.372 - Train accuracy 0.935\n",
            "Epoch: 163/300 - Train loss 1.352 - Train accuracy 0.935\n",
            "Epoch: 164/300 - Train loss 1.364 - Train accuracy 0.920\n",
            "Epoch: 165/300 - Train loss 1.351 - Train accuracy 0.935\n",
            "Epoch: 166/300 - Train loss 1.385 - Train accuracy 0.935\n",
            "Epoch: 167/300 - Train loss 1.354 - Train accuracy 0.935\n",
            "Epoch: 168/300 - Train loss 1.359 - Train accuracy 0.935\n",
            "Epoch: 169/300 - Train loss 1.359 - Train accuracy 0.920\n",
            "Epoch: 170/300 - Train loss 1.348 - Train accuracy 0.935\n",
            "Epoch: 171/300 - Train loss 1.349 - Train accuracy 0.935\n",
            "Epoch: 172/300 - Train loss 1.357 - Train accuracy 0.935\n",
            "Epoch: 173/300 - Train loss 1.358 - Train accuracy 0.935\n",
            "Epoch: 174/300 - Train loss 1.350 - Train accuracy 0.935\n",
            "Epoch: 175/300 - Train loss 1.360 - Train accuracy 0.935\n",
            "Epoch: 176/300 - Train loss 1.364 - Train accuracy 0.920\n",
            "Epoch: 177/300 - Train loss 1.365 - Train accuracy 0.935\n",
            "Epoch: 178/300 - Train loss 1.362 - Train accuracy 0.935\n",
            "Epoch: 179/300 - Train loss 1.350 - Train accuracy 0.935\n",
            "Epoch: 180/300 - Train loss 1.341 - Train accuracy 0.935\n",
            "Epoch: 181/300 - Train loss 1.350 - Train accuracy 0.935\n",
            "Epoch: 182/300 - Train loss 1.357 - Train accuracy 0.935\n",
            "Epoch: 183/300 - Train loss 1.349 - Train accuracy 0.935\n",
            "Epoch: 184/300 - Train loss 1.359 - Train accuracy 0.920\n",
            "Epoch: 185/300 - Train loss 1.359 - Train accuracy 0.920\n",
            "Epoch: 186/300 - Train loss 1.345 - Train accuracy 0.935\n",
            "Epoch: 187/300 - Train loss 1.351 - Train accuracy 0.935\n",
            "Epoch: 188/300 - Train loss 1.337 - Train accuracy 0.935\n",
            "Epoch: 189/300 - Train loss 1.344 - Train accuracy 0.935\n",
            "Epoch: 190/300 - Train loss 1.338 - Train accuracy 0.935\n",
            "Epoch: 191/300 - Train loss 1.351 - Train accuracy 0.935\n",
            "Epoch: 192/300 - Train loss 1.337 - Train accuracy 0.935\n",
            "Epoch: 193/300 - Train loss 1.354 - Train accuracy 0.969\n",
            "Epoch: 194/300 - Train loss 1.356 - Train accuracy 0.920\n",
            "Epoch: 195/300 - Train loss 1.349 - Train accuracy 0.951\n",
            "Epoch: 196/300 - Train loss 1.338 - Train accuracy 0.935\n",
            "Epoch: 197/300 - Train loss 1.352 - Train accuracy 0.935\n",
            "Epoch: 198/300 - Train loss 1.350 - Train accuracy 0.951\n",
            "Epoch: 199/300 - Train loss 1.340 - Train accuracy 0.969\n",
            "Epoch: 200/300 - Train loss 1.356 - Train accuracy 0.935\n",
            "Epoch: 201/300 - Train loss 1.342 - Train accuracy 0.984\n",
            "Epoch: 202/300 - Train loss 1.340 - Train accuracy 0.951\n",
            "Epoch: 203/300 - Train loss 1.341 - Train accuracy 0.984\n",
            "Epoch: 204/300 - Train loss 1.337 - Train accuracy 0.984\n",
            "Epoch: 205/300 - Train loss 1.319 - Train accuracy 0.984\n",
            "Epoch: 206/300 - Train loss 1.319 - Train accuracy 0.984\n",
            "Epoch: 207/300 - Train loss 1.313 - Train accuracy 0.984\n",
            "Epoch: 208/300 - Train loss 1.331 - Train accuracy 1.000\n",
            "Epoch: 209/300 - Train loss 1.322 - Train accuracy 1.000\n",
            "Epoch: 210/300 - Train loss 1.332 - Train accuracy 0.967\n",
            "Epoch: 211/300 - Train loss 1.339 - Train accuracy 1.000\n",
            "Epoch: 212/300 - Train loss 1.317 - Train accuracy 0.984\n",
            "Epoch: 213/300 - Train loss 1.324 - Train accuracy 0.969\n",
            "Epoch: 214/300 - Train loss 1.313 - Train accuracy 1.000\n",
            "Epoch: 215/300 - Train loss 1.301 - Train accuracy 1.000\n",
            "Epoch: 216/300 - Train loss 1.323 - Train accuracy 1.000\n",
            "Epoch: 217/300 - Train loss 1.330 - Train accuracy 1.000\n",
            "Epoch: 218/300 - Train loss 1.314 - Train accuracy 1.000\n",
            "Epoch: 219/300 - Train loss 1.309 - Train accuracy 1.000\n",
            "Epoch: 220/300 - Train loss 1.320 - Train accuracy 0.967\n",
            "Epoch: 221/300 - Train loss 1.292 - Train accuracy 1.000\n",
            "Epoch: 222/300 - Train loss 1.296 - Train accuracy 1.000\n",
            "Epoch: 223/300 - Train loss 1.316 - Train accuracy 0.984\n",
            "Epoch: 224/300 - Train loss 1.307 - Train accuracy 1.000\n",
            "Epoch: 225/300 - Train loss 1.291 - Train accuracy 1.000\n",
            "Epoch: 226/300 - Train loss 1.324 - Train accuracy 1.000\n",
            "Epoch: 227/300 - Train loss 1.325 - Train accuracy 0.984\n",
            "Epoch: 228/300 - Train loss 1.319 - Train accuracy 0.967\n",
            "Epoch: 229/300 - Train loss 1.305 - Train accuracy 0.984\n",
            "Epoch: 230/300 - Train loss 1.296 - Train accuracy 1.000\n",
            "Epoch: 231/300 - Train loss 1.307 - Train accuracy 1.000\n",
            "Epoch: 232/300 - Train loss 1.288 - Train accuracy 1.000\n",
            "Epoch: 233/300 - Train loss 1.302 - Train accuracy 1.000\n",
            "Epoch: 234/300 - Train loss 1.292 - Train accuracy 1.000\n",
            "Epoch: 235/300 - Train loss 1.299 - Train accuracy 1.000\n",
            "Epoch: 236/300 - Train loss 1.317 - Train accuracy 0.967\n",
            "Epoch: 237/300 - Train loss 1.308 - Train accuracy 1.000\n",
            "Epoch: 238/300 - Train loss 1.309 - Train accuracy 0.969\n",
            "Epoch: 239/300 - Train loss 1.304 - Train accuracy 1.000\n",
            "Epoch: 240/300 - Train loss 1.304 - Train accuracy 1.000\n",
            "Epoch: 241/300 - Train loss 1.293 - Train accuracy 1.000\n",
            "Epoch: 242/300 - Train loss 1.289 - Train accuracy 1.000\n",
            "Epoch: 243/300 - Train loss 1.280 - Train accuracy 1.000\n",
            "Epoch: 244/300 - Train loss 1.304 - Train accuracy 1.000\n",
            "Epoch: 245/300 - Train loss 1.329 - Train accuracy 0.951\n",
            "Epoch: 246/300 - Train loss 1.296 - Train accuracy 1.000\n",
            "Epoch: 247/300 - Train loss 1.292 - Train accuracy 1.000\n",
            "Epoch: 248/300 - Train loss 1.303 - Train accuracy 1.000\n",
            "Epoch: 249/300 - Train loss 1.290 - Train accuracy 1.000\n",
            "Epoch: 250/300 - Train loss 1.335 - Train accuracy 0.984\n",
            "Epoch: 251/300 - Train loss 1.316 - Train accuracy 0.967\n",
            "Epoch: 252/300 - Train loss 1.314 - Train accuracy 0.984\n",
            "Epoch: 253/300 - Train loss 1.288 - Train accuracy 1.000\n",
            "Epoch: 254/300 - Train loss 1.296 - Train accuracy 0.984\n",
            "Epoch: 255/300 - Train loss 1.283 - Train accuracy 1.000\n",
            "Epoch: 256/300 - Train loss 1.289 - Train accuracy 1.000\n",
            "Epoch: 257/300 - Train loss 1.286 - Train accuracy 1.000\n",
            "Epoch: 258/300 - Train loss 1.298 - Train accuracy 1.000\n",
            "Epoch: 259/300 - Train loss 1.285 - Train accuracy 1.000\n",
            "Epoch: 260/300 - Train loss 1.306 - Train accuracy 1.000\n",
            "Epoch: 261/300 - Train loss 1.290 - Train accuracy 1.000\n",
            "Epoch: 262/300 - Train loss 1.289 - Train accuracy 1.000\n",
            "Epoch: 263/300 - Train loss 1.291 - Train accuracy 1.000\n",
            "Epoch: 264/300 - Train loss 1.308 - Train accuracy 0.969\n",
            "Epoch: 265/300 - Train loss 1.289 - Train accuracy 1.000\n",
            "Epoch: 266/300 - Train loss 1.286 - Train accuracy 1.000\n",
            "Epoch: 267/300 - Train loss 1.295 - Train accuracy 1.000\n",
            "Epoch: 268/300 - Train loss 1.316 - Train accuracy 0.984\n",
            "Epoch: 269/300 - Train loss 1.296 - Train accuracy 0.984\n",
            "Epoch: 270/300 - Train loss 1.294 - Train accuracy 0.984\n",
            "Epoch: 271/300 - Train loss 1.294 - Train accuracy 1.000\n",
            "Epoch: 272/300 - Train loss 1.286 - Train accuracy 1.000\n",
            "Epoch: 273/300 - Train loss 1.297 - Train accuracy 1.000\n",
            "Epoch: 274/300 - Train loss 1.297 - Train accuracy 0.984\n",
            "Epoch: 275/300 - Train loss 1.302 - Train accuracy 1.000\n",
            "Epoch: 276/300 - Train loss 1.293 - Train accuracy 1.000\n",
            "Epoch: 277/300 - Train loss 1.298 - Train accuracy 1.000\n",
            "Epoch: 278/300 - Train loss 1.284 - Train accuracy 1.000\n",
            "Epoch: 279/300 - Train loss 1.308 - Train accuracy 0.984\n",
            "Epoch: 280/300 - Train loss 1.287 - Train accuracy 1.000\n",
            "Epoch: 281/300 - Train loss 1.278 - Train accuracy 1.000\n",
            "Epoch: 282/300 - Train loss 1.288 - Train accuracy 1.000\n",
            "Epoch: 283/300 - Train loss 1.290 - Train accuracy 1.000\n",
            "Epoch: 284/300 - Train loss 1.286 - Train accuracy 1.000\n",
            "Epoch: 285/300 - Train loss 1.280 - Train accuracy 1.000\n",
            "Epoch: 286/300 - Train loss 1.281 - Train accuracy 1.000\n",
            "Epoch: 287/300 - Train loss 1.285 - Train accuracy 1.000\n",
            "Epoch: 288/300 - Train loss 1.288 - Train accuracy 1.000\n",
            "Epoch: 289/300 - Train loss 1.286 - Train accuracy 1.000\n",
            "Epoch: 290/300 - Train loss 1.289 - Train accuracy 1.000\n",
            "Epoch: 291/300 - Train loss 1.314 - Train accuracy 0.984\n",
            "Epoch: 292/300 - Train loss 1.288 - Train accuracy 1.000\n",
            "Epoch: 293/300 - Train loss 1.280 - Train accuracy 1.000\n",
            "Epoch: 294/300 - Train loss 1.284 - Train accuracy 1.000\n",
            "Epoch: 295/300 - Train loss 1.296 - Train accuracy 1.000\n",
            "Epoch: 296/300 - Train loss 1.287 - Train accuracy 1.000\n",
            "Epoch: 297/300 - Train loss 1.283 - Train accuracy 1.000\n",
            "Epoch: 298/300 - Train loss 1.284 - Train accuracy 1.000\n",
            "Epoch: 299/300 - Train loss 1.285 - Train accuracy 1.000\n",
            "Epoch: 300/300 - Train loss 1.294 - Train accuracy 1.000\n"
          ]
        }
      ],
      "source": [
        "history1 = train(model1,\n",
        "                train_loader,\n",
        "                model1_optimizer,\n",
        "                model1_criterion,\n",
        "                epochs=300\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "aYSrENlwQO-l",
        "outputId": "3172a19b-097f-43c5-eeec-227a14c58d10"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epoch_count = range(1, len(history1['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUPyHPGzQV3B"
      },
      "source": [
        "1.6. Test validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW5uWsxtQSO0"
      },
      "outputs": [],
      "source": [
        "def text_to_tokens(text):\n",
        "    lemma_tokens = []\n",
        "    tokens = nlp(preprocess_clean_text(text))\n",
        "    for token in tokens:\n",
        "        lemma_tokens.append(token.lemma_)\n",
        "    #print(lemma_tokens)\n",
        "    return lemma_tokens\n",
        "\n",
        "def bag_of_words(text, vocab):\n",
        "    tokens = text_to_tokens(text)\n",
        "    bow = [0] * len(vocab)\n",
        "    for w in tokens:\n",
        "        for idx, word in enumerate(vocab):\n",
        "            if word == w:\n",
        "                bow[idx] = 1\n",
        "    #print(bow)\n",
        "    return np.array(bow)\n",
        "\n",
        "def pred_class(text, vocab, labels):\n",
        "    bow = bag_of_words(text, vocab)\n",
        "    words_recognized = sum(bow)\n",
        "\n",
        "    return_list = []\n",
        "    if words_recognized > 0:\n",
        "        x = torch.from_numpy(np.array([bow]).astype(np.float32))\n",
        "        result = model1(x)[0].detach().numpy()\n",
        "        thresh = 0.2\n",
        "        y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
        "        y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        for r in y_pred:\n",
        "            return_list.append(labels[r[0]])\n",
        "            #print(labels[r[0]], r[1])\n",
        "\n",
        "    return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "    tag = intents_list[0]\n",
        "    list_of_intents = intents_json[\"intents\"]\n",
        "    for i in list_of_intents:\n",
        "        if i[\"tag\"] == tag:\n",
        "            result = \"BOT: \" + random.choice(i[\"responses\"])\n",
        "            break\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1vQ7tglQgRD",
        "outputId": "eef00dc4-d181-4ae4-a34e-75abe326e628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: Hola, buen día, se ha comunicado con un centro de denuncias de bajo presupuesto. \n",
            " ¿Cuál es el delito que desea denunciar?\n"
          ]
        }
      ],
      "source": [
        "message = \"Hola buenos dias\"\n",
        "intents = pred_class(message, words, classes)\n",
        "if len(intents) > 0:\n",
        "    result = get_response(intents, dataset)\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jQ0l54dQirT",
        "outputId": "9b30c4a2-17c1-415d-fb88-6d5604fa3257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: Hola, buen día, se ha comunicado con un centro de denuncias de bajo presupuesto. \n",
            " ¿Cuál es el delito que desea denunciar?\n",
            "BOT: Por favor póngase a resguardo, Dígame la dirección\n",
            "BOT: Envío un efectivos al lugar. ¿Algo más en que lo pueda ayudar?\n",
            "BOT: Si pudo identificar al ladrón, por favor dirijase a la comisaria más cercana para realizar un identikit. \n",
            " ¿Algo más en que lo pueda ayudar? \n",
            "BOT: Dígame la dirección\n",
            "BOT: Envío un efectivos al lugar. ¿Algo más en que lo pueda ayudar?\n",
            "BOT: Muy interesante, lo anotaré en mi máquina de escribir invisible\n",
            "BOT: Gracias, adios\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    message = input(\"\")\n",
        "    intents = pred_class(message, words, classes)\n",
        "    if len(intents) > 0:\n",
        "        result = get_response(intents, dataset)\n",
        "        print(result)\n",
        "    else:\n",
        "        print(\"Reformule por favor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCJKTNmNULYg"
      },
      "source": [
        "1.7. Conclusiones\n",
        "\n",
        "El bot es muy limitado en la comprensión de los inputs del usuario. Las preguntas y el texto debe ser muy guionado caso contrario se pierde fácilmente. Aumentar el entrenamiento o profundizar la arquitectura no parecen mejorar sensiblemente los resultados, o incluso los empeoran."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. BOT TF-IDF + Similitud Coseno**"
      ],
      "metadata": {
        "id": "Bfb3ADkzXygO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1. Importo e instalo librerías"
      ],
      "metadata": {
        "id": "XOGmajVdbmgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "import es_core_news_sm\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibvty84Y915L",
        "outputId": "eb560b8e-f551-42fc-d49a-c15caf7dab14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-18 21:55:58.838038: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-18 21:55:58.838098: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-18 21:55:58.838140: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-18 21:56:00.014618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting es-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.6.0/es_core_news_sm-3.6.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Con Beautiful Soup obtengo el texto de un artículo de Wikipedia"
      ],
      "metadata": {
        "id": "QxWOhxXSbrmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para leer y parsear el texto en HTML\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "\n",
        "raw_html = urllib.request.urlopen('https://es.wikipedia.org/wiki/Monstera')\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Parsear artículo, 'lxml' es el parser a utilizar\n",
        "article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "# Encontrar todos los párrafos del HTML (bajo el tag <p>)\n",
        "# y tenerlos disponible como lista\n",
        "article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "article_text = ''\n",
        "\n",
        "for para in article_paragraphs:\n",
        "    article_text += para.text\n",
        "\n",
        "article_text = article_text.lower()"
      ],
      "metadata": {
        "id": "hLGqdJz5FTtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3. Proceso el texto para obtener un corpus y su lematización. Utilizo la librería SpaCy para lematizar en español."
      ],
      "metadata": {
        "id": "WM-9e6-Ib7s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtengo un corpus y su lematización\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "# Primera función de procesamiento de texto\n",
        "def preprocess_clean_text(text):\n",
        "    # Pasar todo el texto a minúsculas\n",
        "    text = text.lower()\n",
        "    # Sacar tildes de las palabras\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    # Quitar caracteres especiales\n",
        "    pattern = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]'\n",
        "    # Quitar números\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "# Segunda función de procesamiento de texto\n",
        "def preprocess_clean_text_final(text):\n",
        "    # Eliminar caracteres y espacios innecesarios\n",
        "    text = re.sub(r'\\[[0-9]*\\]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Quitar caracteres de puntuación\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "# Función de procesamiento\n",
        "def procesamiento(texto):\n",
        "  # Operaciones con RegEx\n",
        "  text = re.sub(r'\\[[0-9]*\\]', ' ', texto)\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "  # Función de preprocesamiento\n",
        "  text = preprocess_clean_text(text)\n",
        "\n",
        "  # Carga del pipeline de procesamiento en español (es)\n",
        "  nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "  # Proceso el texto\n",
        "  doc = nlp(text)\n",
        "\n",
        "  # Obtengo el corpus\n",
        "  corpus = [str(oracion) for oracion in doc.sents]\n",
        "\n",
        "  # Filtro las stop-words del corpus\n",
        "  corpus_procesado = []\n",
        "  for frase in corpus:\n",
        "      doc_frase = nlp(frase)\n",
        "      palabras_sin_stopwords = [token.text for token in doc_frase if not token.is_stop]\n",
        "      frase_procesada = ' '.join(palabras_sin_stopwords)\n",
        "      corpus_procesado.append(frase_procesada)\n",
        "\n",
        "  # El corpus lematizado es:\n",
        "  corpus_lemma = []\n",
        "  for frase in corpus_procesado:\n",
        "    doc_frase = nlp(frase)\n",
        "    frase_lematizada = ' '.join([token.lemma_ for token in doc_frase])\n",
        "    corpus_lemma.append(frase_lematizada)\n",
        "\n",
        "  # Vuelvo a procesar el texto\n",
        "  corpus_lemma_final = []\n",
        "  for frase in corpus_lemma:\n",
        "    frase_limpia = preprocess_clean_text_final(frase)\n",
        "    corpus_lemma_final.append(frase_limpia)\n",
        "\n",
        "  return corpus, corpus_lemma_final"
      ],
      "metadata": {
        "id": "m8dQ2iCr9ile"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos\n",
        "corpus, corpus_lemma = procesamiento(article_text)"
      ],
      "metadata": {
        "id": "A42Tv6MRNfr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4. Introduzco un input del usuario, lo proceso y obtengo una respuesta"
      ],
      "metadata": {
        "id": "6uKVHZ91cLv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplico la misma función para el input del usuario\n",
        "input_usuario = input(\"\")\n",
        "corpus_usuario, lemma_usuario = procesamiento(input_usuario)\n",
        "\n",
        "# Uno el input del usuario al corpus para hacer la similitud coseno\n",
        "corpus_lemma.append(lemma_usuario[0])\n",
        "\n",
        "# Planteo la similitud coseno entre vectores TF-IDF\n",
        "def similitud_documento(corpus, indice):\n",
        "  corpus = np.array(corpus)\n",
        "\n",
        "  # Obtengo listas de términos y términos que las integran\n",
        "  listas_terminos = np.char.split(corpus)\n",
        "  array_terminos = np.concatenate([np.array(lista) for lista in listas_terminos])\n",
        "  terminos, count = np.unique(array_terminos, return_counts=True)\n",
        "\n",
        "  # Obtengo el One Hot Encoding\n",
        "  matriz_OHE = np.array([np.isin(terminos, listas_terminos[i]).astype(int) for i in range(listas_terminos.size)])\n",
        "\n",
        "  # Broadcasting\n",
        "  IDF = np.log10(corpus.size / np.sum(matriz_OHE, axis=0))\n",
        "\n",
        "  # Factor TF\n",
        "  lista_vectores = []\n",
        "  for i in range(listas_terminos.size):\n",
        "    vector = np.zeros(len(terminos), dtype=int)\n",
        "    for palabra in listas_terminos[i]:\n",
        "      coincidencias = (terminos == palabra)\n",
        "      vector = vector + coincidencias\n",
        "    lista_vectores.append(vector)\n",
        "\n",
        "  # Convierto en array\n",
        "  TF = np.array(lista_vectores)\n",
        "\n",
        "  # Obtengo la matriz\n",
        "  matriz_TF_IDF = TF * IDF\n",
        "\n",
        "  # Obtengo el vector de producto punto\n",
        "  dot = np.sum(matriz_TF_IDF[indice]* matriz_TF_IDF, axis=1)\n",
        "\n",
        "  # Norma del vector\n",
        "  norma_vector = np.linalg.norm(matriz_TF_IDF[indice])\n",
        "\n",
        "  # Vector de normas\n",
        "  norma_matriz = np.linalg.norm(matriz_TF_IDF, axis = 1)\n",
        "\n",
        "  # Similitud coseno\n",
        "  vector_similitud = dot / (norma_vector * norma_matriz)\n",
        "\n",
        "  # Ordeno por similitud coseno, el \"-\" ordena de mayor a menor\n",
        "  orden = np.argsort(- vector_similitud)\n",
        "\n",
        "  # Obtengo los documentos ordenados\n",
        "  corpus_ordenado = corpus[orden]\n",
        "\n",
        "  return orden, corpus_ordenado\n",
        "\n",
        "# Aplico la función\n",
        "orden, corpus_ordenado = similitud_documento(corpus_lemma, -1)\n",
        "\n",
        "# Obtengo mi respuesta\n",
        "print(corpus[orden[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upuYjDAXSWAg",
        "outputId": "4df14409-fdef-413e-971b-fae3b7e99e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "De dónde es  originaria la monstera?\n",
            "es originario de mexico y america tropical.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5. Conclusiones\n",
        "\n",
        "El segundo BOT parece mucho más flexible frente a las preguntas del usuario. El principal problema que encuentra es la falta de desarrollo de la lematización en español."
      ],
      "metadata": {
        "id": "MLuns3eWcajN"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cdbad0546734c4b98825419f1a947dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d5e569e1917434d832cfe034cdfd1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4432832534f349aa97296b817b244b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a478e6d050443daab42df2a2016a853": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5184a539290d4a1bb2866d552f02a1b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f30792aa5704c498a1818953ec74fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5184a539290d4a1bb2866d552f02a1b7",
            "placeholder": "​",
            "style": "IPY_MODEL_cd73735126bb4696ab118c6931da84be",
            "value": " 140k/? [00:00&lt;00:00, 9.09MB/s]"
          }
        },
        "a2b575d968864a80a248d4748ea1b215": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f714856e9d4c6b90be1be948d772d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb8a3e16b70a419c81a1ef1cd0d5d57c",
              "IPY_MODEL_ddc708f11390444b9bfda6606f4d667f",
              "IPY_MODEL_7f30792aa5704c498a1818953ec74fc5"
            ],
            "layout": "IPY_MODEL_0d5e569e1917434d832cfe034cdfd1ae"
          }
        },
        "cd73735126bb4696ab118c6931da84be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddc708f11390444b9bfda6606f4d667f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a478e6d050443daab42df2a2016a853",
            "max": 24144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4432832534f349aa97296b817b244b53",
            "value": 24144
          }
        },
        "eb8a3e16b70a419c81a1ef1cd0d5d57c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2b575d968864a80a248d4748ea1b215",
            "placeholder": "​",
            "style": "IPY_MODEL_0cdbad0546734c4b98825419f1a947dd",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: "
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}